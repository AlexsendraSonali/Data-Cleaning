{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **What do you mean by inconsistent Data Entry ?**\n",
        "\n",
        "\n",
        "\n",
        "1.   Varying Date formats\n",
        "2.   Inconsistent Units\n",
        "3.   Spelling and Typographical Errors\n",
        "4.   Inconsistent Categorization\n",
        "5.   Incomplete or Missing Values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Al7pvqE2p5qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "look at the following sample code snippet."
      ],
      "metadata": {
        "id": "rsD_GsFUHHGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhJOySYLpmEU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data into a Pandas DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Handle inconsistent date formats\n",
        "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
        "\n",
        "# Standardize units\n",
        "df['weight'] = df['weight'].str.replace('lbs', '').astype(float)  # Remove 'lbs' and convert to float\n",
        "\n",
        "# Standardize categorical values\n",
        "df['category'] = df['category'].str.lower()  # Convert to lowercase\n",
        "\n",
        "# Correct spelling errors\n",
        "df['name'] = df['name'].str.replace('mispelled', 'misspelled')  # Replace misspelled value\n",
        "\n",
        "# Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)  # Fill missing values with median\n",
        "\n",
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "\n",
        "# Save the cleaned data to a new file\n",
        "df.to_csv('cleaned_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code demonstrates the following techniques for handling inconsistent data:\n",
        "\n",
        "1. Date Format: We use the pd.to_datetime function to convert the 'date' column \n",
        "   to a standardized datetime format.\n",
        "\n",
        "2. Unit Standardization: We remove the 'lbs' unit from the 'weight' column and \n",
        "   convert it to a float for consistent unit representation.\n",
        "\n",
        "3. Categorical Standardization: We convert the 'category' column to lowercase \n",
        "   for consistent categorical values.\n",
        "\n",
        "4. Spelling Correction: We replace a misspelled value in the 'name' column.\n",
        "\n",
        "5. Missing Value Handling: We fill missing values in the 'age' column with the \n",
        "   median value.\n",
        "\n",
        "6. Duplicate Removal: We drop duplicate rows from the DataFrame.\n",
        "\n",
        "7. Saving Cleaned Data: We save the cleaned data to a new CSV file named \n",
        "   'cleaned_data.csv'."
      ],
      "metadata": {
        "id": "tZhp9aye76aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try each of the Techniques.\n",
        "---\n",
        "# I) Categorical Standardization\n"
      ],
      "metadata": {
        "id": "fOV2zTf2HR_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Define the standardized categories\n",
        "standard_categories = {\n",
        "    'category1': 'Category A',\n",
        "    'category2': 'Category B',\n",
        "    'category3': 'Category C',\n",
        "    'category4': 'Category D'\n",
        "}\n",
        "\n",
        "# Standardize the 'category' column\n",
        "data['category'] = data['category'].replace(standard_categories)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "Wrzc7TUfIE4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II) Spelling Correction"
      ],
      "metadata": {
        "id": "NYY9s3L7QF_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import textdistance\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Define a function for spelling correction\n",
        "def correct_spelling(word, dictionary):\n",
        "    corrected_word = min(dictionary, key=lambda x: textdistance.levenshtein.normalized_distance(word, x))\n",
        "    return corrected_word\n",
        "\n",
        "# Load the spelling dictionary\n",
        "spelling_dictionary = ['apple', 'banana', 'orange', 'grape']\n",
        "\n",
        "# Apply spelling correction to the 'fruit' column\n",
        "data['fruit'] = data['fruit'].apply(lambda x: correct_spelling(x, spelling_dictionary))\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "gvGGoke4QRLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III) Duplicate Removal"
      ],
      "metadata": {
        "id": "g6f9QSrDQscG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Remove duplicates based on all columns\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "\n",
        "# Remove duplicates based on specific columns\n",
        "df_no_duplicates = df.drop_duplicates(subset=['column1', 'column2'])\n",
        "\n",
        "# Modify the original DataFrame to remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "Vi43ww9iQxLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge Problem : Find any data inconsistencies in the House price dataset and correct them by applying the techniques mentioned above ."
      ],
      "metadata": {
        "id": "f2jsu5N6Q7rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jM7EuAkPSMzp"
      }
    }
  ]
}